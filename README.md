# 리코 사전과제 02 보고서

## 1. 환경 및 의존성

* **Python**: 3.7 이상 버전
* **Browser**: Google Chrome (최신 버전 권장) 및 대응되는 ChromeDriver
* **Libraries**:
* `selenium`: 웹 자동화 및 동적 요소 제어
* `pandas`: 수집 데이터 구조화 및 파일 저장
* `re`, `time`, `datetime`: 데이터 정제 및 시간 제어 (내장 라이브러리)

---

## 2. 로컬 실행 방법

본 프로젝트는 쉘 스크립트를 통해 환경 확인 및 실행을 자동화하고 있습니다.

### 1) 실행 권한 부여

```bash
chmod +x run.sh

```

### 2) 스크립트 실행

```bash
./run.sh

```

---

## 3. 설계 및 주요 가정

### 1) 컴포넌트 기반 모듈 설계

유지보수와 재사용성을 극대화하기 위해 각 역할을 독립적인 모듈로 분리하였습니다.

* **PageValidator**: 로딩바 감지 및 비동기 팝업 제거 등 환경 정화 담당
* **PageMover**: 메뉴 이동 및 페이지네이션 등 내비게이션 담당
* **OptionSearcher**: 검색어 주입 및 조회 버튼 실행 등 인터페이스 제어 담당
* **DataCrawler**: DOM 탐색, 인덱스 기반 수집 및 데이터 정제 담당
* **DataHandler**: 수집 데이터의 다중 포맷(CSV, JSON) 저장 및 파이프라인 담당

### 2) 모듈 분리 설계 근거

* **관심사 분리(SoC)**: 웹 구조 변경 시 전체 코드가 아닌 해당 도메인 모듈만 수정하여 사이드 이펙트를 최소화합니다.
* **재사용성**: `Validator`나 `Handler` 모듈은 인터페이스가 규격화되어 있어 타 사이트 크롤링 엔진 구축 시 별도의 수정 없이 즉시 사용이 가능합니다.

### 3) 웹 뷰 대기 전략: 정적 대기에서 동적 대기로의 전환

* **문제 진단**: 초기에는 고정된 `time.sleep`을 사용했으나, 네트워크 환경에 따라 로딩 미달로 인한 에러 혹은 불필요한 유효 시간이 발생하는 비효율을 확인했습니다.
* **해결 방안**: Selenium의 `WebDriverWait`를 활용한 **명시적 대기(Explicit Wait)** 전략으로 전면 수정했습니다.
* **결과**: 특정 요소(조회 버튼, 데이터 테이블)가 렌더링되는 시점에 즉시 다음 프로세스를 실행하도록 설계하여, 수집 속도를 개선하고 비동기 로딩 에러를 원천 차단했습니다.

### 4) 데이터 무결성을 위한 요소 타격 전략

* **JS Executor 활용**: UI 상에서 요소가 다른 레이어에 가려져 발생하는 클릭 실패(ElementClickInterceptedException)를 방지하기 위해 JavaScript 직접 실행 방식을 기본 클릭 전략으로 채택했습니다.
* **XPath 기반 데이터 행 필터링**: 테이블 헤더(`th`)와 데이터 행(`td`)이 동일한 `tr` 태그를 사용하는 특성을 고려하여, `//tr[td]` 형태의 XPath 필터링을 적용했습니다. 이를 통해 헤더 행 간섭으로 인한 인덱스 오정렬 문제를 해결했습니다.

### 5) 제품 수준의 예외 처리 및 복구 로직

* **Stale Element 회복 탄력성**: 상세 페이지 진입 후 목록으로 복귀할 때 DOM이 재렌더링되며 기존 요소 객체가 소멸하는 문제를 확인했습니다. 이를 해결하기 위해 매 루프마다 요소 리스트를 최신화(Re-fetching)하는 구조를 구현하여 수집의 연속성을 확보했습니다.
* **확장성 있는 로케이터 전략**: 버튼 클릭 시 특정 ID에만 의존하지 않고, 텍스트 키워드 매칭과 속성 값을 조합한 복합 로케이터를 사용하여 사이트 UI 업데이트에 유연하게 대응하도록 설계했습니다.
* **데이터 정제 자동화**: 수집 단계에서 정규표현식을 활용해 불필요한 제어 문자(줄바꿈, 탭 등)를 제거하는 전처리 로직을 내장하여 바로 분석에 활용 가능한 수준의 데이터를 산출합니다.

### 6) 안정적인 수집을 위한 추가 최적화

* **컨텍스트 기반 팝업 제어**: 단순히 페이지 로딩 직후에만 팝업을 닫는 것이 아니라, 상세 페이지 진입 전후로 발생할 수 있는 비동기 팝업을 감지하기 위해 **다중 반복 감지(Iterative Detection)** 로직을 적용했습니다.
* **내결함성(Fault Tolerance) 설계**: 특정 행(Row) 수집 중 예외가 발생하더라도 전체 프로세스가 중단되지 않도록 `Try-Except` 블록을 세분화하여 설계했습니다. 실패한 항목은 로그에 기록하고 즉시 다음 행으로 넘어감으로써 대량 수집 시의 안정성을 보장했습니다.
* **리소스 최적화**: 자바스크립트 실행(`execute_script`)을 통한 요소 제어를 우선순위에 두어, 물리적 마우스 이벤트 발생 시 생길 수 있는 브라우저 포커스 문제나 오작동 가능성을 원천적으로 차단했습니다.

---

## 4. 한계 및 개선 아이디어

### 1) 현재의 한계점

* **단일 스레드 구조**: 현재 동기식 방식으로 작동하여 대량의 페이지를 수집할 때 속도 측면의 한계가 있습니다.
* **브라우저 의존성**: Chrome 환경에 최적화되어 있어 타 브라우저(Firefox, Edge) 대응 로직이 부족합니다.
* **자동 캡차(CAPTCHA) 대응**: 사이트 보안 정책에 따른 캡차 발생 시 수동 개입이 필요할 수 있습니다.

### 2) 향후 개선 아이디어

* **멀티 프로세싱 적용**: `multiprocessing` 또는 `Selenium Grid`를 도입하여 여러 페이지를 동시 수집함으로써 성능을 획기적으로 개선할 수 있습니다.
* **Headless 모드 및 리소스 최적화**: GUI 없는 모드로 실행하고 불필요한 이미지 로딩을 차단하여 서버 리소스 점유율을 낮출 수 있습니다.
* **에러 알림 시스템**: 수집 중 치명적 오류 발생 시 Slack 또는 이메일로 즉시 알림을 보내는 모니터링 기능을 추가할 수 있습니다.
* **로그 추적 강화**: 단순 터미널 출력을 넘어 `logging` 모듈을 통해 에러 시점의 스크린샷과 스택 트레이스를 기록하는 로깅 시스템 고도화가 가능합니다.
